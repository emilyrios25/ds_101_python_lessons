{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b307b7-89a4-47c5-b019-f4fd73170b96",
   "metadata": {},
   "source": [
    "# Lesson 3: Data Ingest and Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd34e4-227a-44e7-9061-4c7eff82dd99",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc3d53-21de-434d-ba92-e47a0805281d",
   "metadata": {},
   "source": [
    "In this lesson we will learn to load a data file, clean it, and create visualizations with it.\n",
    "\n",
    "In this lesson you will learn:\n",
    "- Load a data file from a local source\n",
    "- Clean and prepare data for analysis\n",
    "- Standard data cleaning practices\n",
    "- Create basic visualizations with Plotly\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a63395-97f5-4cf4-af2b-97e0c8e569bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries for data analysis and visualization\n",
    "import pandas as pd          # For working with data tables (DataFrames)\n",
    "import plotly.express as px   # For creating interactive charts\n",
    "import re                     # For working with text patterns (regular expressions)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d0b795-63bd-459b-bbfe-7afe18beb0ae",
   "metadata": {},
   "source": [
    "## 1 Getting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887a72c4-99ab-49a2-8e95-962e98bfaa49",
   "metadata": {},
   "source": [
    "The most basic step in any data science project is actually getting the data. The pandas library makes this very easy if you are working with tabular data (data organized in rows and columns, like a spreadsheet). \n",
    "\n",
    "We will be working with a CSV (Comma-Separated Values) file containing Reddit posts from the r/JMU subreddit. CSV files are one of the most common formats for storing data because they can be opened by almost any program.\n",
    "\n",
    "We can load the Reddit CSV file using pandas' `.read_csv()` function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d6504e-dfb2-44c6-8a54-ba643f07b27c",
   "metadata": {},
   "source": [
    "### 1.1 Loading a local file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3b684-c46b-48b4-aca5-2d922729c902",
   "metadata": {},
   "source": [
    "To load the CSV file locally, we use the command `pd.read_csv(\"filename.csv\")`. The `pd` is our shorthand for pandas, and `read_csv()` is the function that reads CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a82d45-c742-4c83-8c99-45c0f8e5a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file and display it (but don't save it to a variable yet)\n",
    "pd.read_csv(\"data/reddit_text_analysis_JMU_top_posts_default.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a63cb8-a261-4fd9-a427-6cd7ffc4d5af",
   "metadata": {},
   "source": [
    "**Note** all we did here is load the file into the output screen of Jupyter Notebook, we have not actually stored it as a variable we can work with.\n",
    "\n",
    "We can store it by having the result of the function equal a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32ac01-a783-4fce-a49b-35b4793514e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the CSV file as a variable called 'df' (short for DataFrame)\n",
    "df = pd.read_csv(\"data/reddit_text_analysis_JMU_top_posts_default.csv\")\n",
    "# Display the first 5 rows to see what our data looks like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fc8e9f-a5a7-42b3-a54f-cb25dbfe19ef",
   "metadata": {},
   "source": [
    "The csv file has now been stored as a `DataFrame`. A dataframe is a lot like a spreadsheet with columns and rows, but it has some features to optimize it for data science analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d9a8f-0744-476c-a9dd-a50129eee24d",
   "metadata": {},
   "source": [
    "We can show the content of the data frame by typing `df`. The `.head()` method shows us the first 5 rows, which is useful for getting a quick look at our data.\n",
    "\n",
    "**Note:** You do not have to use the name `df` - this is just a common convention that stands for \"DataFrame\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe893555-0524-4286-b33e-8d7e43727889",
   "metadata": {},
   "source": [
    "## 2 Cleaning the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f99e3-e89e-4df3-83cb-b6c31959c7fd",
   "metadata": {},
   "source": [
    "Before you start doing anything with your data, you want to make sure you get the DataFrame cleaned up. This will make working with the data easier. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a147f-c8e3-4bc5-8ff0-bff011a51809",
   "metadata": {},
   "source": [
    "### 2.1 DataTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9389e90f-1563-48a6-ad0b-d1edd06ef52b",
   "metadata": {},
   "source": [
    "Part of the power of Pandas is that it assumes each column contains the same type of data (all numbers, all text, all dates, etc.). This allows it to make calculations much faster. \n",
    "\n",
    "However, when you import from a CSV file, Pandas is not always able to automatically determine what type of data is in each column. We can check what Pandas decided by using the `.dtypes` property (note: no parentheses needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be304356-2289-4784-b1be-46f8f02bb9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what data types Pandas assigned to each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52eda00-caae-45d4-99c5-cfd75ae10d05",
   "metadata": {},
   "source": [
    "Pandas was able to figure out that the **score** column contains integers, but it had trouble with the other columns. It saved these as generic `objects`, which means they could be strings, numbers, or other types of data formats. \n",
    "\n",
    "This can lead to problems later, so Pandas recommends converting text columns to their special string format called `StringDtype`. This makes for better storage and processing. The code below converts each column to its proper data type:\n",
    "\n",
    "**Syntax Explanation:** To change a column's data type, we use this pattern:\n",
    "- `df['column_name']` - selects the column\n",
    "- `.astype('new_type')` - converts it to the new data type\n",
    "- `df['column_name'] = ...` - saves the converted column back to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff14b70-d6be-489d-87fc-b3d0328aed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each column to its proper data type\n",
    "df['type'] = df['type'].astype('category')        # Post type (post/comment) as category\n",
    "df['title'] = df['title'].astype(pd.StringDtype())  # Title text as string\n",
    "df['text'] = df['text'].astype(pd.StringDtype())    # Post content as string  \n",
    "df['score'] = pd.to_numeric(df['score'])             # Score as number\n",
    "df['date'] = pd.to_datetime(df['date'])              # Date as datetime\n",
    "# Check our new data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f88ff3",
   "metadata": {},
   "source": [
    "Great! Now our columns have proper data types. This is basic housekeeping you should do whenever working with CSV files. While it might seem tedious, it prevents many problems later in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067c344-126d-4da6-8dd0-a7688733bae2",
   "metadata": {},
   "source": [
    "## 3 Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825d0d29-b419-4f19-bc8b-dda8cd9c01cd",
   "metadata": {},
   "source": [
    "Once the dataframe is in order you will want to clean up some of the data. This is usually a recursive process. That is, you usually only figure out that there is an issue with the data when you start working on it. As you keep finding issues, you want to clean these issues earlier in your code, rather than when you run into them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb52ec38-473a-41f2-8c20-d113c95aec51",
   "metadata": {},
   "source": [
    "### 3.1 Removing special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b5aa6-b4c7-4133-89cc-778fa0461648",
   "metadata": {},
   "source": [
    "When working with text data, a common problem is that special characters like emojis can interfere with analysis. These need to be removed because they might cause issues when using tools for **sentiment analysis** or **text processing**. You'll get better results if your data is more standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a3af1-9553-4b8d-bad5-b4b238bb7585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a regex (regular expression) pattern that matches common emoji characters\n",
    "# This pattern covers most emoji Unicode ranges\n",
    "emoji_pattern = r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF]'\n",
    "\n",
    "# Find all rows where the 'text' column contains emojis\n",
    "rows_with_emojis = df[df['text'].str.contains(emoji_pattern, regex=True, na=False)]\n",
    "\n",
    "# Show just the text column of these rows to see the emojis\n",
    "rows_with_emojis[['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28512e2-78e7-40ac-a909-ad5fa8d92dc1",
   "metadata": {},
   "source": [
    "**Note:** In the result above, you can see there are many rows with emojis. We could manually remove these by editing each individual cell, but that would be extremely time-consuming. Instead, we'll use pandas to automatically find and remove all emojis by replacing them with empty text.\n",
    "\n",
    "The code to do this is:\n",
    "```python\n",
    "df['text'] = df['text'].str.replace(emoji_pattern, '', regex=True)\n",
    "```\n",
    "This means: take the 'text' column, find all emojis (using our pattern), and replace them with nothing (empty string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4fe8b-7c3e-4baa-b5a4-20e748912361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all emojis from the text column by replacing them with empty strings\n",
    "df['text'] = df['text'].str.replace(emoji_pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d62eeb-df8e-4ebb-8b2b-450e5734fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if our emoji removal worked by searching for emojis again\n",
    "rows_with_emojis_cleaned = df[df['text'].str.contains(emoji_pattern, regex=True, na=False)]\n",
    "\n",
    "# Display the results (should be empty or much fewer rows)\n",
    "rows_with_emojis_cleaned[['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe603f-2e6c-4de6-9cec-6d1de705b736",
   "metadata": {},
   "source": [
    "As you work with a DataFrame there are always other formatting quirks in the data you will want to take care of. It makes little sense to try to clean everything in advance and hope for the best. Likely, you'll find problems as you go and then make the fixes part of the cleaning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66476a61",
   "metadata": {},
   "source": [
    "# 4 Data Visualization\n",
    "\n",
    "Now that we have clean data with proper data types, we can create visualizations that help us understand patterns in the r/JMU subreddit. Let's start by looking at how posting activity has changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111dded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year-month from the date column for monthly analysis\n",
    "df['year_month'] = df['date'].dt.to_period('M')\n",
    "# Group the data by year-month and post type, then count entries in each group\n",
    "monthly_counts = df.groupby(['year_month', 'type'], observed=True).size().reset_index(name='count')\n",
    "\n",
    "# Convert year_month back to datetime format so Plotly can understand it\n",
    "monthly_counts['year_month'] = monthly_counts['year_month'].dt.to_timestamp()\n",
    "\n",
    "monthly_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d16a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an interactive line chart\n",
    "fig = px.line(monthly_counts, \n",
    "              x='year_month',           # x-axis: time\n",
    "              y='count',                # y-axis: number of posts/comments\n",
    "              color='type',             # separate lines for posts vs comments\n",
    "              title='Number of Posts and Comments per Month on r/JMU',\n",
    "              labels={'count': 'Number of Posts/Comments', 'year_month': 'Year-Month'},\n",
    "              markers=True)             # add dots to the lines\n",
    "\n",
    "# Customize the chart appearance\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Year-Month\",\n",
    "    yaxis_title=\"Number of Posts/Comments\",\n",
    "    legend_title=\"Type\"\n",
    ")\n",
    "\n",
    "# Display the interactive chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dca35b",
   "metadata": {},
   "source": [
    "### 4.1 Keyword Analysis: Do Certain Topics Get Higher Scores?\n",
    "\n",
    "Now let's analyze whether posts containing certain keywords tend to get higher scores (more upvotes). This can tell us what topics are most popular or engaging in the JMU community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbccbf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keywords to analyze - common JMU-related topics\n",
    "keywords = ['tuition', 'covid', 'party', 'football', 'class', 'library', 'campus']\n",
    "\n",
    "# Create a helper function to check if text contains a keyword (case-insensitive)\n",
    "def contains_keyword(text, keyword):\n",
    "    # Handle missing/empty text\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    # Convert both to lowercase to make the search case-insensitive\n",
    "    return keyword.lower() in text.lower()\n",
    "\n",
    "# Store results for each keyword\n",
    "keyword_scores = []\n",
    "\n",
    "for keyword in keywords:\n",
    "    # Create a temporary True/False mask showing which posts contain this keyword\n",
    "    # We don't add this to the DataFrame to keep it clean\n",
    "    has_keyword_mask = df['text'].apply(lambda x: contains_keyword(x, keyword))\n",
    "    \n",
    "    # Calculate the average score for posts containing this keyword\n",
    "    # Use the mask to filter posts that contain the keyword\n",
    "    avg_score = df[has_keyword_mask]['score'].mean()\n",
    "    \n",
    "    # Store the results\n",
    "    keyword_scores.append({\n",
    "        'keyword': keyword,\n",
    "        'score': avg_score\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame for easier plotting\n",
    "keyword_df = pd.DataFrame(keyword_scores)\n",
    "\n",
    "# Create a bar chart showing average scores by keyword\n",
    "fig = px.bar(keyword_df, \n",
    "             x='keyword', \n",
    "             y='score',\n",
    "             title='Average Post Scores by Keyword',\n",
    "             labels={'score': 'Average Score', 'keyword': 'Keyword'})\n",
    "\n",
    "# Customize chart appearance\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Keywords\",\n",
    "    yaxis_title=\"Average Score\",\n",
    "    showlegend=False  # No legend needed for single series\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0b0fc7-c828-48a8-a945-a60a75c3bedc",
   "metadata": {},
   "source": [
    "## 5 Saving Your Work\n",
    "\n",
    "Great work! We now have a clean DataFrame that we can use for further analysis. It's a good practice to save your cleaned data so you don't have to repeat all the cleaning steps every time you want to work with it.\n",
    "\n",
    "There are two main ways to save a DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b946886-e881-48d7-a29d-23512eff1e9e",
   "metadata": {},
   "source": [
    "Whenever you run code in Jupyter, the notebook automatically stores the values of the variables. When you restart, these values are deleted. It is a good practice to save the dataframe variable once you have performed a lot of operations on it. This prevents us from having to run the above code everytime. \n",
    "\n",
    "There are a couple of ways we can save this. We can use the pandas function `to_csv()`, which converts this to a csv file. The advantage of a CSV file is that any computer can read them.\n",
    "</br> \n",
    "There are several issues with CSV files:\n",
    "- They tend to be big\n",
    "- Read and write times can be slow\n",
    "- Will add an empty index column if you are not careful\n",
    "- Unless you specifically indicate the column types, the dtype will get lost. This is a huge pain.\n",
    "\n",
    "Alternatively, we can also save this to a `.pickle` file.\n",
    "\n",
    "**Advantages**\n",
    "\n",
    "- Smaller\n",
    "- Faster\n",
    "- Keeps dtypes\n",
    "\n",
    "**Disadvantages**\n",
    "\n",
    "- Requires Python to open\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e36636a-2584-486f-a101-911554c44631",
   "metadata": {},
   "source": [
    "Saving to pickle file is incredibly simple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a883b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb785a7a-2b30-4885-868e-74d34260f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data/jmu_reddit.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63cf27d-c22a-4822-a252-760f514053f6",
   "metadata": {},
   "source": [
    "The code below should place the file in your working directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
