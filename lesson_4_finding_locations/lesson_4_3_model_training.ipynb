{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "929875e8",
   "metadata": {},
   "source": [
    "## Training a Custom Geoparser Model\n",
    "\n",
    "You may have noticed that some locations in our map are incorrectly identified or resolved. This is a common issue when working with domain-specific text or regional data. The good news is that we can train a custom model to improve accuracy for our specific use case.\n",
    "\n",
    "### Why Train a Custom Model?\n",
    "\n",
    "The pre-trained geoparser works well for general text, but it may struggle with:\n",
    "- **Domain-specific terminology** (academic jargon, local place names)\n",
    "- **Regional variations** (local nicknames for places)\n",
    "- **Context-specific disambiguation** (distinguishing between places with similar names)\n",
    "\n",
    "Let's demonstrate how to create training data and fine-tune the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a209a1",
   "metadata": {},
   "source": [
    "### Step 1: Preparing Training Data\n",
    "\n",
    "Training data must be formatted as a list of dictionaries, where each document contains:\n",
    "- **text**: The raw text content\n",
    "- **toponyms**: List of location mentions with their positions and correct location IDs\n",
    "\n",
    "Here's the required format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training corpus format for JMU-specific locations\n",
    "train_corpus = [\n",
    "    {\n",
    "        \"text\": \"I'm studying at James Madison University in Harrisonburg, Virginia.\",\n",
    "        \"toponyms\": [\n",
    "            {\n",
    "                \"text\": \"Harrisonburg\",\n",
    "                \"start\": 44,  # Starting character position\n",
    "                \"end\": 56,    # Ending character position\n",
    "                \"loc_id\": \"4761681\"  # GeoNames ID for Harrisonburg, VA\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Virginia\",\n",
    "                \"start\": 58,\n",
    "                \"end\": 66,\n",
    "                \"loc_id\": \"6254928\"  # GeoNames ID for Virginia state\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The campus is near downtown Harrisonburg and the Shenandoah Valley.\",\n",
    "        \"toponyms\": [\n",
    "            {\n",
    "                \"text\": \"Harrisonburg\",\n",
    "                \"start\": 28,\n",
    "                \"end\": 40,\n",
    "                \"loc_id\": \"4761681\"\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Shenandoah Valley\",\n",
    "                \"start\": 49,\n",
    "                \"end\": 66,\n",
    "                \"loc_id\": \"4787534\"  # GeoNames ID for Shenandoah Valley\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Training corpus format example created!\")\n",
    "print(f\"Number of training documents: {len(train_corpus)}\")\n",
    "print(f\"First document text: '{train_corpus[0]['text']}'\")\n",
    "print(f\"Number of toponyms in first document: {len(train_corpus[0]['toponyms'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3895a5",
   "metadata": {},
   "source": [
    "### Step 2: Initialize the GeoparserTrainer\n",
    "\n",
    "The `GeoparserTrainer` allows us to fine-tune existing models or train from scratch. Key parameters:\n",
    "\n",
    "- **spacy_model**: Used for tokenization and validating annotations\n",
    "- **transformer_model**: The model to be fine-tuned \n",
    "- **gazetteer**: Must match the knowledge source used for annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659bc5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from geoparser import GeoparserTrainer\n",
    "    \n",
    "    print(\"Initializing GeoparserTrainer...\")\n",
    "    trainer = GeoparserTrainer(\n",
    "        spacy_model=\"en_core_web_trf\",                    # Same as our geoparser\n",
    "        transformer_model=\"dguzh/geo-all-distilroberta-v1\", # Model to fine-tune\n",
    "        gazetteer=\"geonames\"                              # Knowledge source\n",
    "    )\n",
    "    print(\"‚úÖ GeoparserTrainer initialized successfully!\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ùå GeoparserTrainer not available in this version\")\n",
    "    print(\"This is a demonstration of the training process\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing trainer: {e}\")\n",
    "    print(\"This is normal - we're demonstrating the training workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c5f5f3",
   "metadata": {},
   "source": [
    "### Step 3: Training Workflow\n",
    "\n",
    "Here's the complete workflow for training a custom model:\n",
    "\n",
    "1. **Load annotations**: Convert training corpus to GeoDoc objects\n",
    "2. **Train model**: Fine-tune the transformer model\n",
    "3. **Evaluate**: Test performance on evaluation data\n",
    "4. **Use custom model**: Deploy the improved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b133fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Load and annotate training data\n",
    "print(\"üîß TRAINING WORKFLOW DEMONSTRATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# This is demonstration code - actual training would require more data\n",
    "if 'trainer' in locals():\n",
    "    print(\"Step 1: Loading annotations...\")\n",
    "    # train_docs = trainer.annotate(train_corpus)\n",
    "    print(\"‚úÖ Training corpus would be converted to GeoDoc objects\")\n",
    "    \n",
    "    print(\"\\nStep 2: Training the model...\")\n",
    "    # trainer.train(\n",
    "    #     train_docs, \n",
    "    #     output_path=\"models/jmu_custom_geoparser\", \n",
    "    #     epochs=3, \n",
    "    #     batch_size=8\n",
    "    # )\n",
    "    print(\"‚úÖ Model would be fine-tuned and saved\")\n",
    "    \n",
    "    print(\"\\nStep 3: Evaluating performance...\")\n",
    "    # eval_docs = trainer.annotate(eval_corpus)\n",
    "    # eval_docs = trainer.resolve(eval_docs) \n",
    "    # metrics = trainer.evaluate(eval_docs)\n",
    "    print(\"‚úÖ Model performance would be measured\")\n",
    "    \n",
    "    print(\"\\nStep 4: Using the custom model...\")\n",
    "    # custom_geo = Geoparser(\n",
    "    #     transformer_model=\"models/jmu_custom_geoparser\",\n",
    "    #     spacy_model='en_core_web_trf',\n",
    "    #     gazetteer='geonames'\n",
    "    # )\n",
    "    print(\"‚úÖ Custom model would be loaded for improved accuracy\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  GeoparserTrainer not available - this is a demonstration\")\n",
    "    print(\"In practice, you would:\")\n",
    "    print(\"1. Collect 100+ annotated examples\")\n",
    "    print(\"2. Train for 3-5 epochs\") \n",
    "    print(\"3. Evaluate on held-out test data\")\n",
    "    print(\"4. Deploy the improved model\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b5a5b",
   "metadata": {},
   "source": [
    "### Step 4: Evaluation Metrics\n",
    "\n",
    "When training a custom model, you'll get these performance metrics:\n",
    "\n",
    "- **Accuracy**: Proportion of toponyms resolved to the exact correct location\n",
    "- **Accuracy@161km**: Proportion resolved within 161km (100 miles) of correct location  \n",
    "- **MeanErrorDistance**: Average distance in kilometers between predicted and correct locations\n",
    "- **AreaUnderTheCurve**: Distribution of error distances (lower is better)\n",
    "\n",
    "### Alternative: Using the Annotator Web App\n",
    "\n",
    "Instead of manually creating training data, you can use the built-in annotation tool:\n",
    "\n",
    "```bash\n",
    "python -m geoparser annotator\n",
    "```\n",
    "\n",
    "This launches a web interface where you can:\n",
    "- Upload your text files\n",
    "- Click on location mentions to mark them\n",
    "- Select the correct location from suggestions\n",
    "- Export annotations in the proper format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fbab6d",
   "metadata": {},
   "source": [
    "### Tips for Creating Good Training Data\n",
    "\n",
    "**Quality over Quantity:**\n",
    "- Start with 50-100 carefully annotated examples\n",
    "- Focus on problematic cases from your actual data\n",
    "- Include examples of correctly resolved locations too\n",
    "\n",
    "**Domain-Specific Examples:**\n",
    "- Local place names and nicknames  \n",
    "- Ambiguous locations (e.g., \"Richmond\" could be VA, CA, or UK)\n",
    "- Institution-specific references (building names, campus locations)\n",
    "\n",
    "**Geographic ID Sources:**\n",
    "- Use [GeoNames.org](http://geonames.org) to find correct location IDs\n",
    "- Search by place name to get the `geonameid`\n",
    "- Verify coordinates match your intended location\n",
    "\n",
    "**Common Issues to Address:**\n",
    "- University buildings vs. city names\n",
    "- State abbreviations vs. country codes  \n",
    "- Historical vs. modern place names\n",
    "- Colloquial names vs. official names"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
